{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-500720f662d4>\", line 58, in <module>\n",
      "    from tensorflow.keras import Sequential\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "ModuleNotFoundError: No module named 'tensorflow_core'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ModuleNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "  File \"/Users/sonakochkanyan/opt/anaconda3/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_core'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Mar 29 18:31:21 2020\n",
    "\n",
    "@author: sonakochkanyan\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import string as str\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import re\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,cross_val_score, cross_val_predict, train_test_split,StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as detoken\n",
    "#from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import OrdinalEncoder,LabelEncoder,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import iqr\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import stop_words\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "data=pd.read_fwf(\"/Users/sonakochkanyan/Documents/BOT/train2.txt\", header=None)\n",
    "data.fillna(\"\",inplace=True)\n",
    "data['new'] = data.apply(''.join, axis=1)\n",
    "#data=data[\"new\"]\n",
    "\n",
    "data1=pd.read_fwf(\"/Users/sonakochkanyan/Documents/BOT/train1.txt\", header=None)\n",
    "data1.fillna(\"\",inplace=True)\n",
    "data1['new'] = data1.apply(''.join, axis=1)\n",
    "wordsin1=cv.transform(data1['new'])\n",
    "\n",
    "cv=CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
    " \n",
    "# this steps generates word counts for the words in your docs\n",
    "word_count_vector=cv.fit_transform(data['new'])\n",
    "tfidf_transformer=TfidfTransformer(use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "df_idf = pd.DataFrame([tfidf_transformer.idf_, cv.get_feature_names()]).T\n",
    "\n",
    "df_idf.columns=[\"idf_weights\",\"Terms\"]\n",
    "# sort ascending\n",
    "df_idf.sort_values(by=['idf_weights'])\n",
    "\n",
    "train1=tfidf_transformer.transform(wordsin1)\n",
    "train1.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_data = pd.read_csv('/movie_lines.tsv', encoding='utf-8-sig',header=None)\n",
    "line_data = line_data[0].str.split('\\t').to_list()\n",
    "print(f'in total {len(line_data)} utterances')\n",
    "line_data[:4]\n",
    "\n",
    "line_data = [l for l in line_data if len(l) == 5]\n",
    "print(f'in total {len(line_data)} utterances')\n",
    "line_data[:4]\n",
    "\n",
    "lines = pd.DataFrame(line_data, columns=['line_id', 'speaker_id', 'movie_id', 'speaker_name', 'text'])\n",
    "lines = lines.set_index('line_id')\n",
    "lines.loc['L1000']\n",
    "\n",
    "conversation_data = pd.read_csv('/movie_conversations.tsv', encoding='utf-8-sig', sep='\\t', header=None)\n",
    "conversation_data = conversation_data.rename(columns={0: 'speaker1_id', 1: 'speaker2_id', 2: 'movie_id', 3: 'line_ids'})\n",
    "conversation_data\n",
    "\n",
    "def build_conversation(line_ids):\n",
    "    id_list = line_ids[1:-2].replace('\\'', '').split(' ')\n",
    "    def build_utterance(line):\n",
    "        return (line.speaker_id, line.text)\n",
    "    try:\n",
    "        return [build_utterance(lines.loc[line_id]) for line_id in id_list]\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "conversations = [build_conversation(line_ids) for line_ids in tqdm(conversation_data.line_ids)]\n",
    "print(f'in total {len(conversations)} conversations')\n",
    "conversations[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
